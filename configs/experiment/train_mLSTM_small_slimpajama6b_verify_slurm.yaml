# @package _global_
defaults:
  - /data@data_eval.val1: slimpajama_6B_arrayrecord_eval
  - /data@data_eval.val2: synthetic_eval
  - override /parallel: mLSTM165M
  - override /model: mLSTM165M
  - override /data: slimpajama_6B_arrayrecord_train
  - override /optimizer: adamw
  - _self_

# specify the deltas from the defaults:
task_name: short_verification_experiment
batch_size_per_device: 16
context_length: 2048
num_train_steps: 10
lr: 1e-3

n_gpus: 1

logger:
  log_every_n_steps: 2
  loggers_to_use:
    - file_logger

scheduler:
  decay_steps: 0
  warmup_steps: 0
  cooldown_steps: 0

trainer:
  gradient_accumulate_steps: 1

model:
  # Negative value means we infer the vocab size from the tokenizer.
  vocab_size: -1
