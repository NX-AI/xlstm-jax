# @package _global_
defaults:
  - /data@data_train.ds1: slimpajama_627B_arrayrecord_train  # uses gpt2 by default
  - /data@data_eval.ds1: slimpajama_627B_arrayrecord_eval_preprocessed_gpt2
  - override /parallel: mLSTM7B
  - override /model: mLSTM7B
  - override /optimizer: adamw
  - _self_

# specify the deltas from the defaults:
task_name: SPECIFY_TASK_NAME
batch_size_per_device: 8
context_length: 2048
num_epochs: 1000
num_train_steps: 95_000
lr: 5e-4

scheduler:
  warmup_steps: 2000

trainer:
  gradient_accumulate_steps: 1

checkpointing:
  monitor: spaj627B_AR_perplexity
