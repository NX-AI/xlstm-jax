{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"../..\")\n",
        "sys.path.append(\"../../../mlstm_simple_torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from mlstm_simple.from_pretrained import load_from_pretrained\n",
        "from mlstm_simple.model import mLSTM, mLSTMConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "logits_inputs_jax = np.load(\"./logits_inputs_jax.npz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "logits_jax = logits_inputs_jax[\"logits_jax\"]\n",
        "inputs_jax = logits_inputs_jax[\"inputs\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "JAX_CHECKPOINT_PATH = \"/nfs-gpu/xlstm/logs/outputs/xlstm-jax/DCLM/dclm_mLSTMv1_1.3B_ctx8192_2024-11-19T09:24:50/0/checkpoints/checkpoint_95000\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PosixPath('/nfs-gpu/users_home/beck/repos/xlstm-jax3/tests/models/mlstm_simple/mlstm_simple_checkpoint')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SAVE_TORCH_CHECKPOINT_AT = (Path(\".\").parent / \"mlstm_simple_checkpoint\").resolve()\n",
        "SAVE_TORCH_CHECKPOINT_AT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "TORCH_AMP_DTYPE = torch.float32\n",
        "ENABLE_TORCH_AMP = False\n",
        "USE_TORCH_COMPILE = True\n",
        "torch.set_float32_matmul_precision(\n",
        "    \"high\"\n",
        ")  # TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PYTHONPATH=. python scripts/convert_mlstm_checkpoint_jax_to_torch_simple.py --checkpoint_dir \"/nfs-gpu/xlstm/logs/outputs/xlstm-jax/DCLM/dclm_mLSTMv1_1.3B_ctx8192_2024-11-19T09:24:50/0/checkpoints/checkpoint_95000\" --output_path \"/nfs-gpu/users_home/beck/repos/xlstm-jax3/tests/models/mlstm_simple/mlstm_simple_checkpoint\" --checkpoint_type plain\n"
          ]
        }
      ],
      "source": [
        "# ## Convert jax checkpoint to torch:\n",
        "command = f'PYTHONPATH=. python scripts/convert_mlstm_checkpoint_jax_to_torch_simple.py --checkpoint_dir \"{str(JAX_CHECKPOINT_PATH)}\" --output_path \"{str(SAVE_TORCH_CHECKPOINT_AT)}\" --checkpoint_type plain'\n",
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = load_from_pretrained(\n",
        "    checkpoint_path=SAVE_TORCH_CHECKPOINT_AT,\n",
        "    chunkwise_kernel_name=\"chunkwise--triton_xl_chunk\",\n",
        "    sequence_kernel_name=\"native_sequence__triton_step_fused\",\n",
        "    step_kernel_name=\"triton_fused\",\n",
        "    chunk_size=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "mLSTM(\n",
              "  (embedding): Embedding(50304, 2048)\n",
              "  (backbone): mLSTMBlockStack(\n",
              "    (blocks): ModuleList(\n",
              "      (0-23): 24 x mLSTMBlock(\n",
              "        (norm_mlstm): RMSNorm()\n",
              "        (mlstm_layer): mLSTMLayer(\n",
              "          (q): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "          (k): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "          (v): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          (ogate_preact): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          (ogate_act_fn): Sigmoid()\n",
              "          (igate_preact): Linear(in_features=2048, out_features=4, bias=True)\n",
              "          (fgate_preact): Linear(in_features=2048, out_features=4, bias=True)\n",
              "          (mlstm_backend): mLSTMBackend(mLSTMBackendConfig(chunkwise_kernel='chunkwise--triton_xl_chunk', sequence_kernel='native_sequence__triton_step_fused', step_kernel='triton_fused', mode='inference', chunk_size=128, return_last_states=False, autocast_kernel_dtype='bfloat16', eps=1e-06, inference_state_dtype='float32'))\n",
              "          (multihead_norm): MultiHeadLayerNorm()\n",
              "          (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "        )\n",
              "        (norm_ffn): RMSNorm()\n",
              "        (ffn): FeedForward(\n",
              "          (proj_up_gate): Linear(in_features=2048, out_features=5504, bias=False)\n",
              "          (proj_up): Linear(in_features=2048, out_features=5504, bias=False)\n",
              "          (proj_down): Linear(in_features=5504, out_features=2048, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (out_norm): RMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mLSTMConfig(embedding_dim=2048,\n",
            "            num_heads=4,\n",
            "            num_blocks=24,\n",
            "            vocab_size=50304,\n",
            "            use_bias=False,\n",
            "            norm_eps=1e-06,\n",
            "            norm_reduction_force_float32=True,\n",
            "            add_out_norm=True,\n",
            "            qk_dim_factor=0.5,\n",
            "            v_dim_factor=1.0,\n",
            "            mlstm_round_up_to_multiple_of=64,\n",
            "            chunkwise_kernel='chunkwise--triton_xl_chunk',\n",
            "            sequence_kernel='native_sequence__triton_step_fused',\n",
            "            step_kernel='triton_fused',\n",
            "            mode='inference',\n",
            "            chunk_size=128,\n",
            "            return_last_states=False,\n",
            "            autocast_kernel_dtype='bfloat16',\n",
            "            eps=1e-06,\n",
            "            inference_state_dtype='float32',\n",
            "            ffn_proj_factor=2.667,\n",
            "            ffn_round_up_to_multiple_of=64,\n",
            "            gate_soft_cap=15.0,\n",
            "            output_logit_soft_cap=30.0)\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "pprint(model.config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = model.to(\"cuda\")\n",
        "model.config.return_last_states = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W1125 18:19:17.125000 139952932398912 torch/_dynamo/variables/tensor.py:715] [0/0] Graph break from `Tensor.item()`, consider setting:\n",
            "W1125 18:19:17.125000 139952932398912 torch/_dynamo/variables/tensor.py:715] [0/0]     torch._dynamo.config.capture_scalar_outputs = True\n",
            "W1125 18:19:17.125000 139952932398912 torch/_dynamo/variables/tensor.py:715] [0/0] or:\n",
            "W1125 18:19:17.125000 139952932398912 torch/_dynamo/variables/tensor.py:715] [0/0]     env TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1\n",
            "W1125 18:19:17.125000 139952932398912 torch/_dynamo/variables/tensor.py:715] [0/0] to include these operations in the captured graph.\n",
            "W1125 18:19:17.125000 139952932398912 torch/_dynamo/variables/tensor.py:715] [0/0] \n"
          ]
        }
      ],
      "source": [
        "if USE_TORCH_COMPILE:\n",
        "    model = torch.compile(model)\n",
        "with torch.autocast(device_type=\"cuda\", dtype=TORCH_AMP_DTYPE, enabled=ENABLE_TORCH_AMP):\n",
        "    logits_torch, state = model(torch.from_numpy(inputs_jax).to(\"cuda\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "logits_torch_np = logits_torch.float().cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[ 13.566897  ,   0.43551627,  13.216589  , ...,   0.44723246,\n",
              "           0.4433271 ,   0.4394217 ],\n",
              "        [  3.5920599 ,  -8.567479  ,   1.4364008 , ...,  -8.567479  ,\n",
              "          -8.567479  ,  -8.567479  ],\n",
              "        [ 15.932797  ,   2.1525445 ,  12.086428  , ...,   2.1525445 ,\n",
              "           2.1525445 ,   2.1525445 ],\n",
              "        ...,\n",
              "        [  6.519365  ,  -4.619217  ,   4.527646  , ...,  -4.619217  ,\n",
              "          -4.619217  ,  -4.619217  ],\n",
              "        [  1.4286062 ,  -3.4996197 ,   3.2064557 , ...,  -3.4996197 ,\n",
              "          -3.4996197 ,  -3.484206  ],\n",
              "        [  1.4519895 ,   1.327258  ,   0.9684135 , ...,   1.3350551 ,\n",
              "           1.3350551 ,   1.3350551 ]],\n",
              "\n",
              "       [[ 10.641614  ,   5.045358  ,   5.8010306 , ...,   5.045358  ,\n",
              "           5.0149865 ,   5.0149865 ],\n",
              "        [ 14.205258  ,  -1.1556777 ,  11.34495   , ...,  -1.1634786 ,\n",
              "          -1.1556777 ,  -1.1556777 ],\n",
              "        [ 13.61657   ,  -0.9176824 ,  10.967963  , ...,  -0.9215849 ,\n",
              "          -0.9176824 ,  -0.9176824 ],\n",
              "        ...,\n",
              "        [  9.081293  ,  -5.831106  ,   4.0071597 , ...,  -5.831106  ,\n",
              "          -5.8010306 ,  -5.831106  ],\n",
              "        [  4.2217946 , -11.022069  ,  -2.3389935 , ..., -11.022069  ,\n",
              "         -11.022069  , -11.022069  ],\n",
              "        [  4.435989  ,  -7.9901013 ,   0.98011976, ...,  -7.9901013 ,\n",
              "          -7.9901013 ,  -7.9901013 ]],\n",
              "\n",
              "       [[  2.5407736 ,  -3.638254  ,   1.1010677 , ...,  -3.638254  ,\n",
              "          -3.638254  ,  -3.638254  ],\n",
              "        [ 16.288586  ,   0.5780534 ,  13.765019  , ...,   0.5897678 ,\n",
              "           0.5897678 ,   0.5897678 ],\n",
              "        [ 11.022069  ,  -5.590167  ,  10.859508  , ...,  -5.590167  ,\n",
              "          -5.590167  ,  -5.590167  ],\n",
              "        ...,\n",
              "        [  9.75731   ,   0.37302762,   5.9512863 , ...,   0.35935777,\n",
              "           0.3632635 ,   0.38083896],\n",
              "        [  7.0825796 ,  -5.559996  ,   4.0378485 , ...,  -5.590167  ,\n",
              "          -5.559996  ,  -5.559996  ],\n",
              "        [  9.024484  ,  -3.8689587 ,   5.0757194 , ...,  -3.884323  ,\n",
              "          -3.884323  ,  -3.8689587 ]]], dtype=float32)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logits_jax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch_logits_batch1 = logits_torch_np[0]\n",
        "jax_logits_batch1 = logits_jax[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   13,   187, 32682, 14683, 14683,  1768, 31507, 19508,    84,\n",
              "        7994,  7994, 31823, 44199, 31507, 31507,  7994,  4516,   456,\n",
              "       43780, 31823,   342,  2366, 20058,    52, 34948,  3344,  7043,\n",
              "          66, 23790, 40918, 35422,  7043,  9518,  7043,   982, 19185,\n",
              "       30153,   100,  7803,  4431,  9810, 31069,  5729, 30760, 20485,\n",
              "        3162,  3015, 20485,  2233,  5560,  6144, 25518,  3776,  1209,\n",
              "         692,    82,  1385, 25077,  9306,  5629, 20485,  2679,  4435,\n",
              "       23144, 25077,  7422, 23144,   105, 21325,  6144,  1890,  3023,\n",
              "         143, 46979,   608,  5537,  4449, 48779, 37246,   125,  4861,\n",
              "       15912, 23144, 14262, 23144, 25518, 14722, 41805,   103, 14262,\n",
              "         337, 39068,  5537, 18197,  5537,   337,  6144,  2575,  4418,\n",
              "         318,    47, 41014, 46202,   404,  7538, 23068,   139, 14276,\n",
              "           5,  8973,   370,  5537,  9747, 14683,  9467,  4739,    84,\n",
              "        6235, 14262, 20485, 22369,  1216, 15902,  2575, 24724, 22690,\n",
              "        8976, 23144])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.argmax(torch_logits_batch1, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   13,   187, 32682, 14683, 14683,  1768, 31507, 19508,    84,\n",
              "        7994,  7994, 31823, 44199, 31507, 31507,  7994,  4516,   456,\n",
              "       43780, 31823,   342,  2366, 20058,    52, 33470,  3344,  7043,\n",
              "          66, 23790, 40918, 35422,  7043,  9518,  7043,   982, 19185,\n",
              "       30153,   100,  7803,  4431,  9810, 31069,  5729, 30760, 20485,\n",
              "        4317,  3015, 20485,  2233,  5560,  6144, 25518,  3776,  1209,\n",
              "         692,    82,  1385, 25077,  9306,  5629, 20485,  2679,  4435,\n",
              "       23144, 25077,  7422,   114,   105, 21325,  6144,  1890,   430,\n",
              "         143, 46979,     5, 15797,  4449, 48779, 37246,   125,  4861,\n",
              "       15912, 23144, 14262, 23144, 25518, 14722,  7917,   103,  9885,\n",
              "         337, 18197,  5537, 18197,  5537,   337,  6144,  2575,  4418,\n",
              "         318,    47, 41014, 46202,   404,  7538, 22143,   139, 14276,\n",
              "           5, 50076,   370,  5537,  9747, 14683,  9467,  4739,    84,\n",
              "        6235, 14262, 20485, 22369,  1216, 15902,  2575, 24724, 22690,\n",
              "       38512, 23144])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.argmax(jax_logits_batch1, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch1_equal_argmax = np.argmax(torch_logits_batch1, axis=-1) == np.argmax(jax_logits_batch1, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True, False,  True,  True,  True,  True, False,\n",
              "        True,  True, False, False,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True, False,  True, False,\n",
              "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
              "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "       False,  True])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch1_equal_argmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(116, 128)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch1_equal_argmax.sum(), len(batch1_equal_argmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_1_torch_top5 = np.argsort(torch_logits_batch1, axis=-1)[:, -5:]\n",
        "batch_1_jax_top5 = np.argsort(jax_logits_batch1, axis=-1)[:, -5:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[  943,   247,   347,    84,    13],\n",
              "        [  403,   275,   273,    15,   187],\n",
              "        [24748,     0,   187,   273, 32682],\n",
              "        [ 4859, 32682,  7234,  6197, 14683],\n",
              "        [ 6197, 36482, 34401, 19508, 14683],\n",
              "        [ 1559,    67,    84, 21287,  1768],\n",
              "        [17438,  6097, 19508, 14683, 31507],\n",
              "        [  337,   187,    13, 24747, 19508],\n",
              "        [19965, 49357, 19508, 31507,    84],\n",
              "        [40222, 14683,    52, 26745,  7994]]),\n",
              " array([[  403,   247,   347,    84,    13],\n",
              "        [  275,   273,   403,    15,   187],\n",
              "        [24748,     0,   187,   273, 32682],\n",
              "        [42443, 32682,  7234,  6197, 14683],\n",
              "        [ 6197, 36482, 34401, 19508, 14683],\n",
              "        [ 1559,    67,    84, 21287,  1768],\n",
              "        [17438,  6097, 19508, 14683, 31507],\n",
              "        [31507,   187,    13, 24747, 19508],\n",
              "        [19965, 49357, 19508, 31507,    84],\n",
              "        [40222, 14683,    52, 26745,  7994]]))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "indxes = slice(0, 10)\n",
        "\n",
        "batch_1_jax_top5[indxes], batch_1_torch_top5[indxes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.testing.assert_allclose(logits_torch_np, logits_jax, atol=2.0, rtol=1.0)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "xlstmpt240cu124",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
