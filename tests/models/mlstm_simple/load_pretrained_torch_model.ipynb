{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"../..\")\n",
        "sys.path.append(\"../../../mlstm_simple_torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from mlstm_simple.from_pretrained import load_from_pretrained\n",
        "from mlstm_simple.model import mLSTM, mLSTMConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logits_inputs_jax = np.load(\"./logits_inputs_jax.npz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logits_jax = logits_inputs_jax[\"logits_jax\"]\n",
        "inputs_jax = logits_inputs_jax[\"inputs\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "JAX_CHECKPOINT_PATH = \"/nfs-gpu/xlstm/logs/outputs/xlstm-jax/DCLM/dclm_mLSTMv1_1.3B_ctx8192_2024-11-19T09:24:50/0/checkpoints/checkpoint_95000\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SAVE_TORCH_CHECKPOINT_AT = (Path(\".\").parent / \"mlstm_simple_checkpoint\").resolve()\n",
        "SAVE_TORCH_CHECKPOINT_AT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TORCH_AMP_DTYPE = torch.float32\n",
        "ENABLE_TORCH_AMP = False\n",
        "USE_TORCH_COMPILE = True\n",
        "torch.set_float32_matmul_precision(\n",
        "    \"high\"\n",
        ")  # TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ## Convert jax checkpoint to torch:\n",
        "command = f'PYTHONPATH=. python scripts/checkpoint_conversion/convert_mlstm_checkpoint_jax_to_torch_simple.py --checkpoint_dir \"{str(JAX_CHECKPOINT_PATH)}\" --output_path \"{str(SAVE_TORCH_CHECKPOINT_AT)}\" --checkpoint_type plain'\n",
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = load_from_pretrained(\n",
        "    checkpoint_path=SAVE_TORCH_CHECKPOINT_AT,\n",
        "    chunkwise_kernel_name=\"chunkwise--triton_xl_chunk\",\n",
        "    sequence_kernel_name=\"native_sequence__triton_step_fused\",\n",
        "    step_kernel_name=\"triton_fused\",\n",
        "    chunk_size=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "pprint(model.config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = model.to(\"cuda\")\n",
        "model.config.return_last_states = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if USE_TORCH_COMPILE:\n",
        "    model = torch.compile(model)\n",
        "with torch.autocast(device_type=\"cuda\", dtype=TORCH_AMP_DTYPE, enabled=ENABLE_TORCH_AMP):\n",
        "    logits_torch, state = model(torch.from_numpy(inputs_jax).to(\"cuda\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logits_torch_np = logits_torch.float().cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logits_jax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch_logits_batch1 = logits_torch_np[0]\n",
        "jax_logits_batch1 = logits_jax[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.argmax(torch_logits_batch1, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.argmax(jax_logits_batch1, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch1_equal_argmax = np.argmax(torch_logits_batch1, axis=-1) == np.argmax(jax_logits_batch1, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch1_equal_argmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch1_equal_argmax.sum(), len(batch1_equal_argmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_1_torch_top5 = np.argsort(torch_logits_batch1, axis=-1)[:, -5:]\n",
        "batch_1_jax_top5 = np.argsort(jax_logits_batch1, axis=-1)[:, -5:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "indxes = slice(0, 10)\n",
        "\n",
        "batch_1_jax_top5[indxes], batch_1_torch_top5[indxes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.testing.assert_allclose(logits_torch_np, logits_jax, atol=2.0, rtol=1.0)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "xlstmpt240cu124",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
